---
layout: single
title: "Machine Learning: Probabilistic Perspective"
permalink: /wiki/mlapp/
mathjax: true
toc: true
---

# 1 介绍

## 1.1 什么是机器学习, 为啥要它?

> We are drowning in information and starving for knowledge. -- John Naisbitt

我们正在进入一个大数据时代. 网页上10亿; 油管视频暴涨; 人类基因丰富; 沃尔玛每秒交易量上百万, 其数据库数据量达P级($$10^15$$)之多.

大数据需要依靠机器学习来进行自动化数据分析. 具体地, 机器学习指的是, 自动地对数据进行分析, 发现规律, 并以此预测未来的数据, 或者依靠规律对未来进行决策.

本书认为, 概率论是解决此问题的最佳方案. 概率论能够在含有不确定性的问题上发挥作用. 在机器学习中, 不确定性可能是: 在以往的数据的基础上, 最佳的未来预测是什么? 对数据最佳的刻画模型是什么? 我在下一步的最佳策略是什么? 等等. 机器学习相关的概率论和统计理论关联密切, 但是在某些表述和侧重点有所不同.

我们将阐述大量的概率模型, 这些模型适用于不同的数据和任务. 同时, 我们也将阐明大量的算法用于训练和使用这些模型. 本书并非特定问题的参考答案, 而是要为读者提供一个综合的视角来研究概率模型的建模和应用. 我们同样会涉及计算效率的问题, 针对如何将方法扩展到真实的大规模数据的现实场景中, 在其它书籍中会得到更具体地阐述, 这方面书籍有(Rajaraman and Ullman 2011[^1]; Bekkerman et al. 2011[^2])

[^1]: Mining of massive datasets.
[^2]: Scaling up maching learning

值得注意的是, 大量的数据中, 其实真正有效的实际上只有很小一部分. 事实上, 很多领域的数据都具有"长尾"的现象, **长尾**体现在, 极小部分(指种类)的数据是非常常见的, 而大部分数据则是非常少见的. 例如, 谷歌每天有20%的搜索都是过去未见的. 这就意味着本书讨论的核心的关于如何从小规模数据中进行泛化的统计问题, 在大数据背景下, 仍然是非常有用的.

### 1.1.1 机器学习的类型

机器学习主要被分为两种, 其中一种为预测型(**predictive**)或者有监督学习(**supervised learning**). 有监督学习的目标是在给定输入$$\mathbf{x}$$输出$$y$$对集合, $$\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i}^{N}$$, 学习从输入到输出的映射. 这个集合 $$\mathcal{D}$$称为训练集, 而 $$N$$就是样本数.

举个简单的例子, 每个样本的输入 $$\mathbf{x}_i$$ 是一个 $$D$$维的向量, 例如代表身材的身高和体重. 这个向量称为 **特征**, **属性**或者 **协变量**. 一般, 输入$$\mathcal{x}_i$$可以是复杂的数据结构对象, 例如图像, 句子, 电子邮件, 时间序列, 分子, 图等等.

类似的, 输出或者称为**响应值**可以是任何形式的数据, 但在大多数方法, $$y_i$$是一个**类别**或者属于某个有限集合的**代表**, 例如用$$y_i \in \{1, ... C\}$$ 代表男性, 女性; 或者是浮点数$$\y_i$$, 代表收入. 当 $$y_i$$ 是类别的是, 问题被称为分类, 或者是模式识别, 当 $$y_i$$ 是个浮点数时, 问题则是回归问题. 另一类问题, 被称为有序回归, 这类问题中, 输出空间 $$\mathcal{Y}$$ 有序, 想评价等级 A-F.

另一种类型的机器学习称为**描述性**或者**无监督学习**. 在这类问题中, 我们只有输入集合 $$\mathcal{D} = \{(\mathbf{x}_i\}_{i}^{N}$$, 目标是找到数据中隐含的模式. 这类问题有时候被称为**知识挖掘**(**knowledge discovery**). 目前这类问题, 缺乏全面的定义, 毕竟我们并不知道我们要寻找什么样的模式. 而且没有明确评价指标来估计误差(不想监督学习, 可以直接对比模型预测与真实的标签).

机器学习其实还有第三种, 称为**强化学习**. 该类方法主要为了解决, 在奖惩环境下如何行动. (就像婴儿学步). 虽然我们将在第5.7节中讨论决策论, 但是强化学习不在本书的讨论范围. 

## 1.2 监督学习

下面开始讨论机器学习中运用最为广泛的监督学习.

### 1.2.1 分类

本节, 我们讨论分类问题. 分类问题的目标是学习输入 $$\mathbf{x}$$ 到输出 $$y$$ 的映射, 其中 $$y\in \{1, \cdots, C\}$$, $$C$$是类别总数. 如果 $$C = 2$$ 则问题是**二分类**问题(此时 $$y\in \{0, 1\}$$); 如果 $$C > 2$$ 则问题是**多分类**问题. 如果各个类别不是互斥的(例如, 某个人可以同时被分类为高大的, 和强壮的), 此时这类问题称之为**多标签分类**问题, 但是这类问题更恰当地应当看做多个相关的二分类问题(即通常说的**多输出模型**). 当我们提到**分类问题**时, 默认多分类问题采用单个输出方式, 除非另有说明.

分类问题通常被表述为**函数逼近**问题. 学习过程是用带标签的训练集估计函数 $$f$$ 概函数有 $$y = f(x)$$, 然后用这个估计得的函数 $$\hat{f}$$(戴帽子表示估计得函数) 对新的的输入中进行类别预测 $$\hat{y} = \hat{f} x) $$. 对新的输入的预测能力称之为**范化能力**.

#### 1.2.1.1 例子

我们来看一个简单的例子, 如 Figure1.1(a) 所示. 有两种类型的物体, 分别标签为 0 和 1. 输入为彩色的图形. 这些图像可以用 $$D$$ 维的特征或者属性, 这些特征用 $$N\times D$$ 的矩阵表示, 如 Figure1.1(b) 所示. 输入特征 $$\mathbf{x}$$ 可以是离散, 连续的或者二者兼而有之. 除此之外, 我们还有对应的输出标签 $$y$$.

![](/assets/img/MLAPP-Figure-1.1.png){:height="300px"}

在图 Figure1.1 中, 测试样本是一个蓝色的月牙, 一个黄色圆环和一个蓝色的箭头. 这些形状在训练样本中都未曾见过. 我们需要用训练集**范化**到这些未曾见过的样本. 我们有理由猜测, 蓝色的月牙的标签应该为 $$y=1$$, 因为训练集中所有的蓝色的图形标签都为 1. 黄色的圆环则更难分类, 因为训练集中黄色的图形部分标签为 $$y=0$$, 部分为 $$y=0$$, 圆形图案也有两种标签. 因此, 黄色的圆环的标签不明确. 类似地, 蓝色的箭头的标签也不明确.

#### 1.2.1.2 概率预测的必要性

为了解决上述的模棱两可的困境, 我们需要预测概率. 本书假设读者掌握一定的概率论概念. 如果没有可以参看第二章的内容. 

给定训练集 $$\mathcal{D}$$ 和 输入向量 $$\mathbf{x}$$ 所有可能的标签的概率表示为 $$p(y \mid \mathbf{x}, \mathcal{D})$$. 这实际上是一个长度为 $$C$$ 的向量, 其中 $$C$$ 是类别数. 对于二分类问题, 直接给出一个数 $$p(y=1 \mid \mathbf{x}, \mathcal{D}$$ 就足够了, 因为 $$p(y=1 \mid \mathbf{x}, \mathcal{D}) + p(y=0 \mid \mathbf{x}, \mathcal{D}) = 1$$. 从表达式可见, 概率是训练集和输入向量的条件概率. 当模型参与预测是, 我们还可以显示地将概率表示为所使用的模型的条件概率: $$p(y \mid \mathbf{x}, {M}, \mathcal{D})$$, 但是如果上下文明显表明包含模型, 我们会将 $$M$$ 省略.

有了概率, 我们可以计算概率最大的标签作为"最佳估计", 表达式如下:

$$
  \hat{y} = \hat{f}(x) = \overset{C}{\underset{c=1}{\operatorname{argmax}}} \ p(y=c| \mathbf{x}, \mathcal{D}) \tag{1.1}
$$

这就是可能性最大的标签, 称之为分布 $$p(y \mid \mathbf{x}, \mathcal{D})$$ 的**众数**(**mode**); 这也就是**最大后验概率估计**(**M**aximum **A** **P**osteriori estimation). 使用概率最大的标签作为结果在直觉上是合理的, 5.7节中将进行更正式的阐述.

现在假设这样的情形, 黄色的圆环的概率 $$p(\hat{y} \mid \mathbf{x}, \mathcal{D})$$ 远低于 1.0. 也就是说, 我们没有十足的把我给出我们的答案, 此时可能我们直接说"我不知道"比给一个我们自己也不确信的答案来的更好一些. 这些情况在一些医学和金融场景尤为重要, 毕竟在这些应用场景中, 我们不值得冒险, 这些将在 5.7 章中进行解释. 还有其它的应用场景评估风险也非常重要, 毕竟这些场景中可能稍有不慎会让你输钱.

#### 1.2.1.3 真实案例

分类问题应用广泛, 解决了许多有趣的, 高难度的问题. 下面举一些现实例子.

**文档分类和垃圾邮件过滤**

**文档分类**(**document classification**) 目标是将文档, 如网页, 邮件等归类. 垃圾邮件过滤是其中一个特例, 是一个文档二分类问题, 将邮件分为是垃圾邮件 $$y = 1$$ 和 不是 $$y=0$$.

![](/assets/img/MLAPP-Figure1.2.png){:height="480px"}

# 2 概率论

## 2.1 引言

> Probability theory is nothing but common sense reduced to calculation. -- Pierre Laplace, 1812

什么是概率, 两种角度:

1) **频率**角度. 例如抛硬币, 正反面的频率相当
2) **贝叶斯**角度. 在这个角度中, 概率用来表述事件的**不确定性**. 在这个角度下, 我们可以认为硬币出现正反面是等可能的.

贝叶斯可以用来建模那些没有或无法长期频率观测的事件. 例如估计北极冰盖在2020年会不会融化的概率, 这件事可能不发生, 发生也只会发生一次.


## 2.2 概述

### 2.2.1 离散随机变量

$$p(A)$$ 表示事件 $$A$$ 为真的概率, 满足 $$0 \le p(A) \le 1$$. $$p(\overline{A})$$ 为 $$A$$ 的互斥事件, 有 $$p(\overline{A}) = 1 - p(A)$$. $$A=1$$ 常常表示为 A 为真, $$A=0$$ 表示 A 事件为否.

对于**离散随机变量** $$X\in \mathcal{X}$$, 用 $$p(X = x)$$ 表示事件 $$X = x$$的概率, 也可以缩略成  $$p(x)$$, 这里 $$p()$$ 称之为[**概率质量函数**](https://zh.wikipedia.org/wiki/%E6%A6%82%E7%8E%87%E8%B4%A8%E9%87%8F%E5%87%BD%E6%95%B0)([pmf](https://en.wikipedia.org/wiki/Probability_mass_function)). 概率满足  $$0 \le p(x) \le 1$$ 并且 $$\sum_{x\in\mathcal{X}}p(x) = 1$$. 图2.1 展示了两个概率质量函数, 它们的**状态空间**为 $$\mathcal{X}=\{1, 2, 3, 4, 5\}$$, 其中左边(a)为一个均匀分布, $$p(x) = 1/5$$, 右边(b)为一个退化分布, $$p(x)=\mathbb{I}(x=1)$$, 其中 $$\mathbb{I}$$ 是一个二元指示函数(indicator function). 这个分布表明, $$X$$ 永远等于1, 是一个常数.

![](/assets/img/MLAPP-Figure2.1.png){:height="320px"}

#### 2.2.2.1 并集事件的概率

$$
\begin{aligned}
    p(A \vee B) &= p(A) + p(B) - p(A \wedge B) \\
                &= p(A) + p(B), 当 A, B为互斥事件 
\end{aligned}  \tag{2.1} 
$$

#### 2.2.2.2 联合概率



联合概率定义如下

$$
 p(A, B) = p(A \wedge B) = p(A|B)p(B) = p(B|A)p(A) \tag{2.3}
$$

又称[**乘法公式**](https://en.wikipedia.org/wiki/Chain_rule_(probability)). 给定联合概率分布 p(A, B), 定义**边缘概率分布**如下:

$$
p(A) = \sum_{b}p(A, B) = \sum_{b} p(A \mid B)p(B=b) \tag{2.4}
$$

又称**加法公式**. 

乘法公式可以多次应用, 得到**链式公式**, 如下

$$
p(X_{1:D}) = p(X_1)p(X_2 \mid X1)p(X_3 \mid X_2, X_1)p(X_4 \mid X_1, X_2, X_3) ... p(X_D \mid X_{1:D-1}) \tag{2.5}
$$


公式中 $$1:D$$ 含义与 `matlab` 相同, 表示集合 $$\{1, 2, ..., D\}$$

#### 2.2.2.3 条件概率

条件概率是在事件B成立下事件A的概率, 表示如下:

$$
p(A \mid B) = \frac{p(A, B)}{p(B)} 如果 p(B) > 0 \tag{2.6}
$$

> *译者注:  
> 如果 $$p(B) = 0$$, $$p(A) = 0$$*

### 2.2.3 贝叶斯公式

综合上节条件概率, 乘法公式和加法公式, 我们可以推出**贝叶斯公式**, 也成**贝叶斯定理**:

$$
p(X = x \mid Y = y) = \frac{p(X = x, Y = y)}{p(Y = y)} = \frac{p(X = x)p(Y = y \mid X = x)}{\sum_{x'}p(X = x')p(Y=y \mid X=x')} 
\tag{2.7}
$$

#### 2.2.3.1 示例: 医学诊断


假设你进行乳腺癌检测, 结果呈阳性, 那么你有多大概率患有乳腺癌呢? 当然这取决于检测的可靠性有多少. 现在已知检测的**敏感性(sensitivity)**为80%, 它表示, 如果你患有乳腺癌, 检测结果有0.8的概率呈现阳性, 即

$$
p(x=1 \mid y = 1) = 0.8
$$

其中 $$x = 1$$ 表示检测呈阳性, $$y=1$$ 表示患有乳腺癌. 此时多数人可能认为, 你患乳腺癌的概率为 80%. 但这是错误的. 主要原因在于, 这样的推断忽略了人群患乳腺癌的先验概率是很低的, 它等于:

$$
p(y = 1) = 0.004
$$

忽略先验概率称之为**基本比率谬误**. 同时我们还应该将检测的假阳性或称**误检**(false positive)概率进去. 遗憾的是, 误检的检测手段误检概率是很高的: 

$$
p(x = 1 \mid y = 0) = 0.1
$$

综合以上, 我们可以利用贝叶斯公式得出正确的答案:

$$
\begin{aligned}
    p(y=1 | x = 1) &= \frac{p(x=1 \mid y=1)p(y=1)}{p(x=1 \mid y=1)p(y=1) + p(x=1 \mid y=0)p(y=0)} \\
    &= \frac{0.8 \times 0.004}{0.8 \times 0.004 + 0.1 \times 0.996} = 0.031
\end{aligned}
$$

其中 $$p(y=0) = 1 - p(y=1)= 0.996$$. 也就是说, 即使你的检测是阳性, 你患有乳腺癌的概率依然只有3.1%. 

#### 2.2.3.2 示例: 生成式分类器

我们可以把上节医学诊断的例子, 拓展到对任何特征向量 $$x$$ 分类中:

$$
p(y = c \mid \mathbf{x}, \mathbf{\theta}) = \frac{p(y = c \mid \mathbf{\theta})p(\mathbf{x} \mid y=c, \mathcal{\theta})}{\sum_{c'}p(x \mid y = c', \mathbf{\theta})p(y = c' \mid \mathbf{\theta})}
$$

这就是**生成式分类器**, 如此称呼是因为它使用的**类别先验** $$p(y=c)$$, 利用**类别的条件密度** $$p(x \mid y = c$$ 确定了数据如何生成. 这类模型将在 第3章和第4章进行探讨. 另一类方法则直接拟合类别的后验概率 $$p(y=c \mid x)$$, 称之为**判别式分类器**. 这两类方法的优缺点将在 8.6 章节进行讨论.

### 2.2.4 独立和条件独立

两组事件 $$X$$ 和 $$Y$$ **无条件独立**(unconditionally independent) 或者说**边缘独立**(marginally independent), 记作 $$X\bot Y$$. 如图2.2所示, 两个独立事件的联合概率等于边缘概率的乘积, 即:

$$
X \bot Y \Longleftrightarrow p(X, Y) = p(X)p(Y)
$$


![](/assets/img/MLAPP-Figure2.2.png){: height="360px"}

无条件独立的情况很少, 多数情况下, 变量之间会互相影响. 这种影响, 肯能来自于某个共同的变量. 当且仅当有如下情形时, 我们说事件X和事件Y在Y发生的条件下独立, 这就是**条件独立**(conditionally independent, CI):

$$
X \bot Y\mid Z \Longleftrightarrow p(X, Y \mid Z) = 
p(X \mid Z)p(Y \mid Z) \tag{2.15}
$$

在第10章讨论的图模型里, 我们可把这样的情形表示成一个图 $$X-Z-Y$$, 也就是说, 事件X和事件Y的独立性在事件Z条件下成立.


条件独立还有如下特征:

**定理 2.2.1:**    $$X \bot Y \mid Z$$ 成立, 当且仅当存在函数 $$g$$, 和$$h$$, 对于所有的 $$x$$, $$y$$, $$z$$ 且 $$p(z)> 0$$ 满足:

$$
p(x, y \mid z) = g(x, z)h(y, z) \tag{2.16}
$$

条件独立是建立大型概率模型的基础. 如下章节都会用到条件独立假设:

- 3.5节 贝叶斯分类器
- 17.2节 马尔科夫模型
- 10章 图模型

### 2.2.5 连续随机变量

假设有随机变量$$X$$, 计算$$X$$落入范围 $$a \le X \le b$$的概率. 首先我们定义事件 $$A = (X \le a), B = (X \le b) 和 W = (a < X \le b)$$. 显然我们有$$B= A \vee W$$, 因为事件A和W互斥, 根据加法公式, 我们有:

$$
p(B) = p(A) + p(W) \tag{2.17}
$$

所以
$$
p(W) = p(B) - p(A) \tag{2.18}
$$

定义**概率累计函数**(cumulative distribution function, cdf)函数 $$F(q) \triangleq p(X \le q)$$, 该函数单调递增. 图2.3(a)展示了一个例子. 基于此定义, 有

$$
p(a < X \le b) = F(b) - F(a) \tag{2.19}
$$

再定义 $$f(x) = \frac{d}{dx}F(x)$$(假设导数存在), 称之为**概率密度函数**(probability density function, cdf). 于是有

$$
P(a \lt X \le b) = \int_a^b f(x)dx \tag{2.20}
$$

当间隔足够小, 有:

$$
P(x \le X \le x+dx) \approx p(x)dx
$$

其中要求 $$p(x) \ge 0$$, 而 $$p(x) > 1$$是可以的, 只要最终的积分为1. 例如, 有**均匀分布**:

$$
Unif(x \mid a, b) = \frac{1}{b - a} \mathbb{I}(a \le x \le b)
$$

如果 a 设为 0, b 设为 $$\frac{1}{2}$$, 对于 $$x \in [0, \frac{1}{2}]$$ 就有 $$p(x) = 2$$.

### 2.2.6 分位数

概率累计函数单调递增, 存在反函数 $$F^{-1}$$. $$F^{-1}(\alpha)$$ 是概率累计位置的函数, $$\alpha$$ 即为 $$F$$ 的分位数. 其中 $$F^{-1}(0.5)$$ 是分布的**中值**.

cdf的反函数有时被用来计算**尾部概率**(tail area probabilities). 假设我们$$\Phi$$表示高斯分布 $$\mathcal{N}(0, 1)$$ 的概率累计函数. 高斯分布左右对称, 我们砍去左右的尾部概率, 一边一半. 如果我们要保留95%的概率质量, 左右就各坎 2.5%. 即有

$$
(\Phi^{-1}(0.025), \Phi^{-1}(0.975)) = (-1.96, 1.96)
$$

更一般地, 对于正态分布 $$\mathcal{N}(\mu, \sigma^2)$$, 区间 $$(\mu - 1.96\sigma, \mu + 1.96\sigma)$$ 包含了95%的概率质量. 一般我们会近似地写作 $$\mu \pm 2\sigma$$

### 2.2.7 均值和方差

均值或称期望, 用 $$\mu$$ 表示. 离散变量其定义为 $$E(X) \triangleq \sum_{x\in\mathcal{X}}xp(x) $$, 对于连续随机变量, 定义为 $$E(X) = \int_{\mathcal{X}}xp(x)dx$$. 如果积分无界, 则均值不存在.

**方差**可理解为分布的*广度*, 用 $$\sigma^2$$ 表示. 定义如下:

$$
\begin{aligned}
    Var[X] &\triangleq E[(X - \mu)^2] = \int (x - \mu)^2 p(x) dx \\
    &= \int x^2 p(x) dx - 2 \mu \int xp(x)dx + \int \mu^2 p(x) dx =E(X^2) - \mu^2 
\end{aligned}
\tag{2.24 2.25} 
$$

由此可得

$$
E(X^2)= \mu^2 + \sigma^2
$$

标准差定义为方差的平方根, 与 X 量纲一致, 颇有用.

$$
std[X] \triangleq \sqrt{Var[X]}
$$

## 2.3 常见的离散分布

### 2.3.1 二项分布与伯努利分布

假设抛 $$n$$ 次硬币, 其中正面朝上的次数为 $$X$$, 显然 $$X\in \{0, 1, ... n\}$$, 则我们说 $$X$$ 服从二项式分布, 记作 $$X \sim Bin(n, \theta)$$, 其中 $$\theta$$ 硬币正面朝上的概率. 二项式分布的概率质量函数为:

$$
Bin(k \mid n, \theta) \triangleq \pmatrix{n \\ k} \theta^k(1 - \theta)^{n-k}
$$

其中

$$
\pmatrix{n \\ k} = \frac{n!}{(n-k)!k!}
$$

理解为从 $$n$$ 次选取 $$k$$ 次正面朝上的选法种数, 该系数称作**二项式系数**. 图2.4 展示了一些二项式分布的例子. 二项式分布的均值和方差分别为:

$$
mean = \theta , var = n\theta(1-\theta)
$$

如果我们只丢一次这样的硬币, 正面朝上的次数为 $$X\in \{ 0, 1\}$$, 服从**伯努利分布**或称**0 1 分布**, 记作 $$X  \sim  Ber(\theta)$$, 概率质量函数定义如下:

$$
\begin{aligned}
    Ber(1 \mid \theta) &= \theta^{\mathbb{I}(x=1)}(1 - \theta)^{\mathbb{I}(x=0)} \\
    &= 
    \begin{cases}
        \theta, ~~~~~~~~~~\text{if } x = 1, \\
        1-\theta, ~~~\text{if } x = 0
    \end{cases}
\end{aligned}

$$


![](/assets/img/MLAPP-Figure2.4.png){:width="640px"}


### 2.3.2 多项分布和分类分布


**推导:**  
$$
  \pmatrix{n \\ x_1}\theta_1^{x_{1}} \cdot \pmatrix{n - x_1 \\ x_2} \theta_2^{x_{2}} \cdots  \pmatrix{n - x_1 - x_2 \cdots x_{n-1} \\ x_n} \theta_n^{x_{n}}
$$

![](/assets/img/MLAPP-Figure2.5.png){:width="640px"}